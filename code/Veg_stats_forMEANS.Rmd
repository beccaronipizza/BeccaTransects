---
title: "Veg_stats_forMEANS"
author: "Becca Morris"
date: "2024-04-01"
output: html_document
---
```{r}
library(readxl)
library(ggplot2)
library(ggpubr)
library(tidyverse)
library(broom)
library(AICcmodavg)
library(lme4)
library(car)
```

```{r}
setwd("~/GitHub/BeccaTransects/data")

vegmetadata <- read_xlsx("~/GitHub/BeccaTransects/data/VegData_raw.xlsx", sheet = "Metadata")
vegdata <- read_xlsx("~/GitHub/BeccaTransects/data/VegData_raw.xlsx", sheet = "Data_2")
```

#Main DF:
```{r}
##
#calculating change in cover for total veg (where total can exceed 25) and then the mean change for each zone, shoreline end, and log presence:

vegdata2 <- vegdata %>% 
  mutate_at(c('MeIn', 'DiGr', 'RaSa', 'CaMa', 'SaSo', 'Lolium', 'FrSa', 'Fabiaceae','Vicia', 'Sonc', 'Xant', 'LeTr', 'Ranunculus', 'Taraxacum', 'Coytote_Bush','BoMa', 'DiSp', 'AtPx', 'PoAr', 'AcMa', 'GrSt', 'MixedSeedlings','GrGR', 'Melilotus', 'MePo'), as.numeric) %>% 
  mutate_if(is.numeric, list(~replace_na(., 0))) %>%
  select(-BaGr_Type_1, -BaGr_Type_2, -Coytote_Bush, -Wrack, -Tot_Num_Species, -Shoot_Density, -Length_centimeters, -Patch_Type) %>% 
  mutate(SaSp = SaPa + SaDe) %>% 
  mutate(SaPa_new = SaPa + ((SaPa/SaSp)*PicklePups)) %>%      #combine and distribute picklepup category amongst the two species
  mutate(SaDe_new = SaDe + ((SaDe/SaSp)*PicklePups)) %>% 
  mutate(across(c('SaPa_new', 'SaDe_new'),(~replace_na(., 0)))) %>%   #where the calculations above = 0, R was turning them into NaN's
  mutate(SaPa_new = ifelse(SaPa > 25, 25, SaPa_new)) %>%      #these lines tell it where these columns exceed 25 quad's, to just set them = to 25
  mutate(SaDe_new = ifelse(SaDe_new > 25, 25, SaDe_new)) %>% 
  mutate(Grass = GrGR + LeTr + MixedSeedlings) %>% 
  mutate(Grass = ifelse(Grass > 25, 25, Grass)) %>% 
  mutate(BaGr = rowSums(across(BaGr_1:BaGr_2), na.rm = T)) %>% 
  select(-BaGr_1, -BaGr_2) %>% 
  mutate(Total_Veg = 25-BaGr) %>%  #Total_Veg is simply what is remaining after subtracting the bare ground
  #mutate(across(SpFo:Total_Veg, ~ .x*4)) %>%  #makes percentages out of the counts
  mutate(across(everything(), ~replace(.x, is.nan(.x), 0))) %>%
  select(-c('GrGR','LeTr','MixedSeedlings','PicklePups', 'SaPa','SaDe','SaSp')) %>% #removed SaSp column so it would not be counted as part of 'Total_Veg2' column in addition to the SaPa and SaDe columns
  rename(SaPa = SaPa_new, SaDe = SaDe_new) %>% #putting their original names back after the calculation above
  mutate(across(c('SaPa', 'SaDe'), ~round(., 0))) %>% 
  #relocate(Log_Zone, .after = last_col()) %>%    #if you want to use log zone you need to upload the vegdata spreadsheet using the Data_2_LZ sheet.
  #mutate(across(SpFo:Grass, ~ .x*4)) %>% #makes everything into percentages
  mutate(Total_Veg2 = rowSums(across(SpFo:Grass))) %>% #Total_Veg2 adds all the total quadrants each species is present in and combining them all into one total count (can exceed 100)
  mutate(Date = paste0(Year, "-", Month)) #%>% 
#filter(is.na(Log_Zone))  #remove rows where the quad that lands on log and the one quad that lands above and below are marked as "R" for remove
#filter(!Total_Veg2 == 0)  #remove all rows where total_veg is equal to 0

vegmetadata %>% 
  select(Transect_ID, Shoreline_End, Log_Presence)

vegdatamerged <- full_join(vegdata2, vegmetadata, by = "Transect_ID") %>% 
  select(-c(...9:...12)) 
```


# TOTAL VEG CHANGE:
```{r}
TotalVeg_change <- vegdatamerged[(vegdatamerged$Log_Presence != "reference"),] %>% #remove reference logs from calculation
  #filter(Date == "2022-August" | Date == "2023-August") %>%
  filter(Date == "2023-August") %>%
  group_by(Transect_ID, Quadrat) %>% 
  arrange(Date) %>% #arrange by date so the calculations can be made below
  mutate(initial_count = first(Total_Veg),
         final_count = last(Total_Veg),
         count_difference = (final_count - initial_count)) %>%
  ungroup() %>% 
  filter(!(Date == "2022-August")) %>%  #this just removes the June count_difference data bc it is a repeat for the august data and we only need one calculation
  group_by(Date, Zone, Shoreline_End, Log_Presence) %>% 
  #summarize(mean_cover = mean(count_difference, na.rm = TRUE),   #from here down you calculate summary statistics
   #         sd_cover = sd(count_difference, na.rm = TRUE),
    #        n_cover = n()) %>% 
  #mutate(se_cover = sd_cover/sqrt(n_cover)) %>% 
  mutate(across(where(is.numeric), ~round(., 0))) %>% 
  mutate(Shoreline_End = factor(Shoreline_End, levels = c("west", "east")),
         Zone = factor(Zone, levels = c("U", "M", "L")),
         Log_Presence = factor(Log_Presence, levels = c("log", "no log")))
```

#ANOVA
```{r}
hist(TotalVeg_change$Total_Veg2) #use count_difference or Total_Veg2?


#ANOVA with interactive effects:
Interactive <- aov(count_difference ~ Shoreline_End*Log_Presence*Zone,
            data = TotalVeg_change)

summary(Interactive)


#Check for Homoscedacity:
plot(Interactive)
shapiro.test(Interactive$residuals)


#ANOVA with additive effects:
Additive <- aov(count_difference ~ Log_Presence+Shoreline_End+Zone,
            data = TotalVeg_change)

summary(Additive)

#Check for Homoscedacity:
plot(Additive)




#Find the best fit model:
model.set <- list(Interactive, Additive)
model.names <- c("Interactive", "Additive")

aictab(model.set, modnames = model.names) #the model with the lowest AIC value is the best fit for the data
#RESULTS: The interactive model has a lower AIC value.


#Find out which groups are statistically different from each other:
tukey.Interactive <- TukeyHSD(Additive)
tukey.Interactive



#Kruskal-Wallis test: ???
kruskal.test(mean_cover ~ Log_Presence+Shoreline_End,
            data = TotalVeg_change)


#Plot results in a graph... https://www.scribbr.com/statistics/anova-in-r/
```




#GLMM with Julie:
```{r}
#GLMM with interactive effects:

#LOAD the data using the count difference between Aug 2022 and Aug 2023!
Interactive_glmm <-  glmer.nb(count_difference + 26 ~ Shoreline_End*Log_Presence*Zone+(1|Quadrat:Zone),
                     data = TotalVeg_change)

#LOAD only August 2023 data for this one:
Interactive_glmm3 <-  glmer.nb(Total_Veg ~ Shoreline_End*Log_Presence*Zone+(1|Quadrat:Zone),
                      data = TotalVeg_change) #difference in veg in all three zones west vs east  **USE August 2023 data ONLY

Anova(Interactive_glmm3)
emmeans(Interactive_glmm3, pairwise ~ Shoreline_End|Zone)


sim_res <- simulateResiduals(Interactive_glmm) # generates fitted model residuals
plot( sim_res ) # draws diagnostic plots along with diagnostic tests
testDispersion ( sim_res )
```

#GLMM mixture of stuff I tried before and with Julie. See final Julie stuff above.
```{r}
#GLMM with interactive effects:
Interactive_glmm <-  glmer.nb(count_difference + 26 ~ Shoreline_End*Log_Presence*Zone+(1|Quadrat:Zone),
                     data = TotalVeg_change)

#NOT USEFUL: NO EFFECT OF LOG:
#Interactive_glmm2 <-  glmer.nb(count_difference + 26 ~ Log_Presence*Zone+(1|Quadrat:Zone:Shoreline_End), #accounting for known variability in shoreline end and 
                       #data = TotalVeg_change)

Interactive_glmm3 <-  glmer.nb(Total_Veg ~ Shoreline_End*Log_Presence*Zone+(1|Quadrat:Zone),
                      data = TotalVeg_change) #difference in veg in all three zones west vs east  **USE August 2023 data ONLY

#NOT USEFUL: NO EFFECT OF LOG: 
#Interactive_glmm4 <-  glmer.nb(Total_Veg ~ Log_Presence*Zone+(1|Quadrat:Zone:Shoreline_End),
                      #data = TotalVeg_change) #more interested in log presence than location

Anova(Interactive_glmm4)
emmeans(Interactive_glmm3, pairwise ~ Shoreline_End|Zone) 

# check_normality(Interactive_glmm) dont need* Only for Gaussian models
check_heteroscedasticity(Interactive_glmm)

sim_res <- simulateResiduals( Interactive_glmm) # generates fitted model residuals
plot( sim_res ) # draws diagnostic plots along with diagnostic tests
testOverdispersion ( sim_res )


#Check for Homoscedacity:

      #For residuals vs fitted plot:

      # Compute residuals
      residuals <- resid(Interactive_glmm3)
      # Extract fitted values
      fitted_values <- fitted(Interactive_glmm3)
      # Plot residuals vs fitted values
      plot(fitted_values, residuals, xlab = "Fitted values", ylab = "Residuals", 
           main = "Residuals vs Fitted Values")
      abline(h = 0, col = "red", lty = 2)  # Add horizontal line at y = 0
      

      #For QQ plot:
      
      #Compute residuals:
      residuals <- resid(Interactive_glmm)
      # Generate theoretical quantiles
      theoretical_quantiles <- qnorm(ppoints(length(residuals)))
      # Create QQ plot
      qqnorm(residuals)
      qqline(residuals)
      


#GLMM with additive effects:
Additive_glmm <- glmer(count_difference ~ Shoreline_End+Log_Presence+Zone+(1|Transect_ID), 
                     family = gaussian(link = "identity"), 
                     data = TotalVeg_change)

summary(Additive_glmm)

#For residuals vs fitted plot:

      # Compute residuals
      residuals <- resid(Additive_glmm)
      # Extract fitted values
      fitted_values <- fitted(Additive_glmm)
      # Plot residuals vs fitted values
      plot(fitted_values, residuals, xlab = "Fitted values", ylab = "Residuals", 
           main = "Residuals vs Fitted Values")
      abline(h = 0, col = "red", lty = 2)  # Add horizontal line at y = 0
      

      #For QQ plot:
      
      #Compute residuals:
      residuals <- resid(Interactive_glmm3)
      # Generate theoretical quantiles
      theoretical_quantiles <- qnorm(ppoints(length(residuals)))
      # Create QQ plot
      qqnorm(residuals)
      qqline(residuals)
```







# Total SpFo Change:
```{r}
TotalSpFo_change <- vegdatamerged[(vegdatamerged$Log_Presence != "reference"),] %>% #remove reference logs from calculation
  filter(Date == "2022-August" | Date == "2023-August") %>%
  group_by(Transect_ID, Quadrat) %>% 
  arrange(Date) %>% #arrange by date so the calculations can be made below
  mutate(initial_count = first(SpFo),
         final_count = last(SpFo),
         count_difference = (final_count - initial_count)) %>%
  ungroup() %>% 
  filter(!(Date == "2022-August")) %>%  #this just removes the June count_difference data bc it is a repeat for the august data and we only need one calculation
  group_by(Date, Zone, Shoreline_End, Log_Presence) %>% 
  summarize(mean_cover = mean(count_difference, na.rm = TRUE),   #from here down you calculate summary statistics
            sd_cover = sd(count_difference, na.rm = TRUE),
            n_cover = n()) %>% 
  mutate(se_cover = sd_cover/sqrt(n_cover)) %>% 
  mutate(across(where(is.numeric), ~round(., 0))) %>% 
  mutate(Shoreline_End = factor(Shoreline_End, levels = c("west", "east")),
         Zone = factor(Zone, levels = c("U", "M", "L")),
         Log_Presence = factor(Log_Presence, levels = c("log", "no log")))
```
```{r}
hist(TotalSpFo_change$mean_cover)
shapiro.test(TotalSpFo_change$mean_cover) #p-value <0.05 (0.01204) suggesting a non-normal distribution. p > 0.05, accept null that samples come from a normal distribution.


#ANOVA with interactive effects:
Interactive <- aov(mean_cover ~ Shoreline_End*Log_Presence*Zone,
            data = TotalSpFo_change)

summary(Interactive)
plot(Interactive)


#ANOVA with additive effects:
Additive <- aov(mean_cover ~ Log_Presence+Shoreline_End+Zone,
            data = TotalSpFo_change)

summary(Additive)
plot(Additive)




#Find the best fit model:
model.set <- list(Interactive, Additive)
model.names <- c("Interactive", "Additive")

aictab(model.set, modnames = model.names) #the model with the lowest AIC value is the best fit for the data
#RESULTS: The two way model has the lowest AIC value and carries 95% of the AIC weight, which means it explains 95% of the total variation in the dependent variable that can be explained by both models.


#Check for homoscedasticity:
plot(TwoWay) #Some outliers having an influence?


#Kruskal-Wallis test: ???
kruskal.test(mean_cover ~ Log_Presence+Shoreline_End,
            data = TotalVeg_change)
```
